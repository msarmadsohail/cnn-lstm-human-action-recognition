# Human Action Recognition using CNN-LSTM

[![Python](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/)
[![PyTorch](https://img.shields.io/badge/PyTorch-1.x-red.svg)](https://pytorch.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

## ğŸ¯ Project Overview

Deep learning models for **Human Action Recognition (HAR)** from video sequences using the **UBFC dataset**.

**Developed during:** CNN Internship at SEECS, NUST (Jun - Aug 2023)

This project explores multiple deep architectures including **ConvLSTM** and **LRCN (Long-term Recurrent Convolutional Network)** for temporal video understanding.

---

## ğŸ“‹ Objectives

- Video preprocessing & frame extraction
- CNN-based spatial feature learning
- LSTM/ConvLSTM-based temporal modeling
- Performance comparison between architectures

---

## ğŸ“Š Dataset

**UBFC Video Dataset** - Labeled human action video samples decomposed into frame sequences for temporal deep learning models.

---

## ğŸ—ï¸ Architectures Implemented

### **1. ConvLSTM**
Hybrid network combining:
- Convolutional layers for spatial feature extraction
- LSTM layers for temporal sequence learning
- Dense layers for classification

### **2. LRCN (Long-term Recurrent Convolutional Network)**
- CNN per-frame feature extractor
- LSTM layers for temporal evolution
- Fully-connected layers for classification

---

## ğŸ“ Repository Structure

```
â”œâ”€â”€ exploratory_notebooks/        # Initial data exploration
â”œâ”€â”€ implementation_1/             # First architecture attempt
â”œâ”€â”€ implementation_2/             # Improved model + training logs
â”œâ”€â”€ implementation_3/             # Final optimizations
â”œâ”€â”€ Human_Action_Recognition_using_CNN_+_LSTM.ipynb  # Complete workflow
â”œâ”€â”€ LICENSE
â””â”€â”€ README.md
```

---

## ğŸš€ Workflow

**Step 1:** Visualizing Data & Labels  
**Step 2:** Dataset Preprocessing (frame extraction, resizing, augmentation)  
**Step 3:** Train/Test Split  
**Step 4:** ConvLSTM Model (construct, train, evaluate)  
**Step 5:** LRCN Model (construct, train, compare)  
**Step 6:** Testing on YouTube Videos (real-world generalization)

---

## ğŸ“Š Results Summary

âœ… Both ConvLSTM and LRCN successfully learned temporal patterns  
âœ… LRCN showed smoother convergence (decoupled CNN extraction)  
âœ… Strong performance on test data and YouTube videos  
âœ… Action classes with higher motion variation performed better

---

## ğŸ› ï¸ Tech Stack

- **Language:** Python 3.8+
- **Frameworks:** PyTorch, Keras, TensorFlow
- **Libraries:** NumPy, Matplotlib, OpenCV
- **Dataset:** UBFC (Human Action Recognition)

---

## ğŸ‘¨â€ğŸ’» Author

**Muhammad Sarmad Sohail**  
Data Engineer | Machine Learning Engineer  
Research Intern | SEECS, NUST

msarmadsohail@gmail.com  
[LinkedIn](https://linkedin.com/in/msarmadsohail) | [GitHub](https://github.com/msarmadsohail) | [Portfolio](https://msarmadsohail.github.io)

---

## ğŸ“ License

MIT License - see [LICENSE](LICENSE) file
